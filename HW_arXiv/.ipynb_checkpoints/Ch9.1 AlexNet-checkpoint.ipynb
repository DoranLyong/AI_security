{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guhnoo Yun, 2019010823 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time \n",
    "sys.path.insert (0,'..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 11x11 Conv, s=4, p=1, #96 \n",
    "* MaxPool \n",
    "* 5x5 Conv, p=2, #256 \n",
    "* MaxPool \n",
    "* 3x3 Conv, p=1, #384 \n",
    "* 3x3 Conv, p=1, #384 \n",
    "* 3x3 Conv, p=1, #384\n",
    "* MaxPool\n",
    "* Dropout\n",
    "* Linear(4096)\n",
    "* Dropout\n",
    "* Linaer(4096)\n",
    "* Linear(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            Flatten(),\n",
    "            nn.Dropout(p=0.5,inplace=True),\n",
    "            nn.Linear(in_features=6400,out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.5,inplace=True),\n",
    "            nn.Linear(in_features=4096,out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=4096,out_features=10)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Checking the architecture \n",
    "* Observe the output shape of each layer.\n",
    "\n",
    "Input tensor's shape should be (B, C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d Output shape:\t torch.Size([1, 96, 54, 54])\n",
      "ReLU Output shape:\t torch.Size([1, 96, 54, 54])\n",
      "MaxPool2d Output shape:\t torch.Size([1, 96, 26, 26])\n",
      "Conv2d Output shape:\t torch.Size([1, 256, 26, 26])\n",
      "ReLU Output shape:\t torch.Size([1, 256, 26, 26])\n",
      "MaxPool2d Output shape:\t torch.Size([1, 256, 12, 12])\n",
      "Conv2d Output shape:\t torch.Size([1, 384, 12, 12])\n",
      "ReLU Output shape:\t torch.Size([1, 384, 12, 12])\n",
      "Conv2d Output shape:\t torch.Size([1, 384, 12, 12])\n",
      "ReLU Output shape:\t torch.Size([1, 384, 12, 12])\n",
      "Conv2d Output shape:\t torch.Size([1, 256, 12, 12])\n",
      "ReLU Output shape:\t torch.Size([1, 256, 12, 12])\n",
      "MaxPool2d Output shape:\t torch.Size([1, 256, 5, 5])\n",
      "Flatten Output shape:\t torch.Size([1, 6400])\n",
      "Dropout Output shape:\t torch.Size([1, 6400])\n",
      "Linear Output shape:\t torch.Size([1, 4096])\n",
      "ReLU Output shape:\t torch.Size([1, 4096])\n",
      "Dropout2d Output shape:\t torch.Size([1, 4096])\n",
      "Linear Output shape:\t torch.Size([1, 4096])\n",
      "ReLU Output shape:\t torch.Size([1, 4096])\n",
      "Linear Output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(size=(1,1,224,224))    # (B, C, H, W)\n",
    "\n",
    "for layer in net:\n",
    "    X=layer(X)\n",
    "    print(layer.__class__.__name__,'Output shape:\\t',X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reading Data (Fashion-MNIST)\n",
    "* Preprocess: Fashion-MNIST has 28x28 pixels -> upsample them to 244x244\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os \n",
    "\n",
    "import torchvision \n",
    "from torchvision import transforms \n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None, root=os.path.join(os.getcwd(), 'datasets', 'fashion-mnist')):\n",
    "    \"\"\"Download the Fashion-MNIST dataset and then load into memory.\"\"\"\n",
    "    root = os.path.expanduser(root)\n",
    "    transformer = []\n",
    "    if resize:\n",
    "        transformer += [transforms.Resize(resize)]\n",
    "    transformer += [transforms.ToTensor()]\n",
    "    transformer = transforms.Compose(transformer)\n",
    "\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, transform=transformer, download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, transform=transformer, download=True)\n",
    "    num_workers = 0 if sys.platform.startswith('win32') else 4\n",
    "\n",
    "    train_iter = DataLoader(mnist_train, batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_iter = DataLoader(mnist_test, batch_size, shuffle=False, num_workers=num_workers)\n",
    "    return train_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu():\n",
    "    \"\"\"If GPU is available, return torch.device as cuda:0; else return torch.device as cpu.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, device=torch.device('cpu')):\n",
    "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
    "    net.eval()  # Switch to evaluation mode for Dropout, BatchNorm etc layers.\n",
    "    acc_sum, n = torch.tensor([0], dtype=torch.float32, device=device), 0\n",
    "    for X, y in data_iter:\n",
    "        # Copy the data to device.\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            y = y.long()\n",
    "            acc_sum += torch.sum((torch.argmax(net(X), dim=1) == y))\n",
    "            n += y.shape[0]\n",
    "    return acc_sum.item()/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ch5(net, train_iter, test_iter, criterion, num_epochs, batch_size, device, lr=None):\n",
    "    \"\"\"Train and evaluate a model with CPU or GPU.\"\"\"\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train() # Switch to training mode\n",
    "        n, start = 0, time.time()\n",
    "        train_l_sum = torch.tensor([0.0], dtype=torch.float32, device=device)\n",
    "        train_acc_sum = torch.tensor([0.0], dtype=torch.float32, device=device)\n",
    "        for X, y in train_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, y = X.to(device), y.to(device) \n",
    "            y_hat = net(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                y = y.long()\n",
    "                train_l_sum += loss.float()\n",
    "                train_acc_sum += (torch.sum((torch.argmax(y_hat, dim=1) == y))).float()\n",
    "                n += y.shape[0]\n",
    "\n",
    "        test_acc = evaluate_accuracy(test_iter, net, device) \n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\\\n",
    "            % (epoch + 1, train_l_sum/n, train_acc_sum/n, test_acc, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda:0\n",
      "epoch 1, loss 0.0120, train acc 0.422, test acc 0.728, time 31.7 sec\n",
      "epoch 2, loss 0.0056, train acc 0.732, test acc 0.777, time 39.0 sec\n",
      "epoch 3, loss 0.0046, train acc 0.784, test acc 0.806, time 65.9 sec\n",
      "epoch 4, loss 0.0040, train acc 0.812, test acc 0.831, time 66.3 sec\n",
      "epoch 5, loss 0.0036, train acc 0.830, test acc 0.844, time 66.4 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs, device = 0.01, 5, try_gpu()\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "net.apply(init_weights)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=0.0005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_ch5(net, train_iter, test_iter, criterion, num_epochs, batch_size, device, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env] *",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
