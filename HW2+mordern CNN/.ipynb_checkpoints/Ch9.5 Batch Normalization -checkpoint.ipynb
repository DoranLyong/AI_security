{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Training deep models is difficult and getting them to converge in a reasonable amount of time can be tricky.\n",
    "* ```Batch_normalization```, one popular and effective technique that has been found to accelerate the convergence of deep nets\n",
    "* Standardizing input data to each have a mean of zero(0) and variance of one(1) typically makes it easier to train models since parameters are a-priori at a similar scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For a typical MLP or CNN, as we train the model, the activations in intermediate layers of the network may assume different orders of magnitude (both across nodes in the same layer, and over time due to updating the model's parameters). \n",
    "* ***ex)*** 1층 = 10, 2층 = 100, 3층 = 1000 -> (10, 100, 1000) different orders \n",
    "* he authors of the batch normalization technique postulated that this drift in the distribution of activations could hamper the convergence of the network. Intuitively, we might conjecture that if one layer has activation values that are 100x that of another layer, we might need to adjust learning rates adaptively per layer (or even per node within a layer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Deeper networks are complex and easily capable of overfitting. This means that regularization becomes more critical.\n",
    "* Empirically, we note that even with ```dropout```, models can overfit badly and we might benefit from other ```regularization``` heuristics.\n",
    "* 경험적(heuristics)이라는 것에 유의. 아직까지 수학적으로 증명은 못하고, 추측만 하는 단계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ```Batch_Normalization_Layers```\n",
    "* The batch normalization methods for fully-connected layers and convolutional layers are slightly different. This is due to the dimensionality of the data generated by convolutional layers.\n",
    "*  one of the key differences between BN and other layers is that BN operates on a a ```full minibatch``` at a time (otherwise it cannot compute the mean and variance parameters per batch).\n",
    "    * 전체 배치에 대한 Normalization을 가정하면, 1억 만 장의 사진을 한 번에 정규화 하려면? 시간이 아주 많이 걸리겠지?\n",
    "    * 그래서, 차선으로 딱 미니배치 끼리 정규화 적용 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ```BN``` for ```Fully-connected_Layers```\n",
    "    * Linear -> ```BN``` -> activation  \n",
    "    * ,or Linear -> activation -> ```BN```\n",
    "    \n",
    "<br/>\n",
    "\n",
    "* ```BN``` for ```Convolutional_Layers```\n",
    "    * Conv -> ```BN``` -> activation \n",
    "    * ,or Conv -> activation -> ```BN```\n",
    "    \n",
    "*  If the convolution computation outputs multiple channels, we need to carry out batch normalization for each of the outputs of these channels, and each channel has an independent scale parameter and shift parameter, both of which are scalars.\n",
    "    * ***ex)*** Assume that there are $m$ examples in the mini-batch. \n",
    "    * On a single channel, we assume that the height and width of the convolution computation output are $p$ and $q$, respectively.\n",
    "    * We need to carry out batch normalization for $m \\times p \\times q$ elements in this channel simultaneously. \n",
    "    * In other words, we use the means and variances of the $m \\times p \\times q$ elements in this channel rather than one per pixel.\n",
    "    \n",
    "<br/>\n",
    "\n",
    "* ```BN``` during prediction \n",
    "    * At prediction time, we might not have the luxury of computing offsets per batch—we might be required to make one prediction at a time (입력 batch_size=1)\n",
    "    * Secondly, the uncertainty in $\\mathbf{\\mu}$ and $\\mathbf{\\sigma}$, as arising from a minibatch are undesirable once we've trained the model. \n",
    "    * One way to mitigate this is to compute more stable estimates on a larger set for once (e.g. via a moving average) and then fix them at prediction time.\n",
    "* Consequently, ```BN``` behaves differently during training and at test time (recall that ```dropout``` also behaves differently at train and test times)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "* Implementation the ```BN``` layer with ```torch.Tensor``` from scratch \n",
    "* This retains the scale parameter ***gamma*** and the shift parameter ***beta*** involved in gradient finding and iteration, and it also maintains the mean and variance obtained from the ***moving average***, so that they can be used during model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum):\n",
    "    \"\"\"\n",
    "    Use torch.is_grad_enabled() to determine \n",
    "    whether the current mode is training mode or prediction mode \n",
    "    \"\"\"\n",
    "    if not torch.is_grad_enabled():\n",
    "        \"\"\"\n",
    "        If it is the prediction mode, directly use the mean and variance\n",
    "        obtained from the incoming moving average \n",
    "        \"\"\"\n",
    "        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)\n",
    "    else:\n",
    "        assert len(X.shape) in (2, 4)\n",
    "        if len(X.shape) == 2:\n",
    "            \"\"\"\n",
    "            When using a fully-connected layer, calculate the mean and\n",
    "            variance on the feature dimension\n",
    "            \"\"\"\n",
    "            mean = X.mean(dim=0)\n",
    "            var = ((X - mean) ** 2).mean(dim=0)\n",
    "        else:\n",
    "            \"\"\"\n",
    "            When using a two-dimensional convolutional layer, calculate the\n",
    "            mean and variance on the channel dimension (axis=1). Here we\n",
    "            need to maintain the shape of X, so that the broadcast operation\n",
    "            can be carried out later\n",
    "            \"\"\"\n",
    "            mean = X.mean(dim=(0, 2, 3), keepdim=True)\n",
    "            var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True)\n",
    "        \"\"\"\n",
    "        In training mode, the current mean and variance are used for the\n",
    "        standardization\n",
    "        \"\"\"    \n",
    "        X_hat = (X - mean) / torch.sqrt(var + eps)\n",
    "        \n",
    "        # Update the mean and variance of the moving average\n",
    "        moving_mean = momentum * moving_mean + (1.0 - momentum) * mean\n",
    "        moving_var = momentum * moving_var + (1.0 - momentum) * var\n",
    "    Y = gamma * X_hat + beta  # Scale and shift\n",
    "    return Y, moving_mean, moving_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, num_features, num_dims, **kwargs):\n",
    "        super(BatchNorm, self).__init__(**kwargs)\n",
    "        if num_dims == 2:\n",
    "            shape = (1, num_features)\n",
    "        else:\n",
    "            shape = (1, num_features, 1, 1)\n",
    "        \n",
    "        \"\"\"\n",
    "        The scale parameter and the shift parameter involved in gradient\n",
    "        finding and iteration are initialized to 0 and 1 respectively\n",
    "        \"\"\"\n",
    "        self.gamma = nn.Parameter(torch.ones(shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(shape))\n",
    "        \n",
    "        \"\"\"\n",
    "        All the variables not involved in gradient finding and iteration are\n",
    "        initialized to 0 on the CPU\n",
    "        \"\"\"\n",
    "        self.moving_mean = torch.zeros(shape)\n",
    "        self.moving_var = torch.zeros(shape)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        If X is not on the CPU, copy moving_mean and moving_var to the\n",
    "        device where X is located\n",
    "        \"\"\"\n",
    "        if self.moving_mean.device != X.device:\n",
    "            self.moving_mean = self.moving_mean.to(X.device)\n",
    "            self.moving_var = self.moving_var.to(X.device)\n",
    "        \n",
    "        # Save the updated moving_mean and moving_var\n",
    "        Y, self.moving_mean, self.moving_var = batch_norm(\n",
    "            X, self.gamma, self.beta, self.moving_mean,\n",
    "            self.moving_var, eps=1e-5, momentum=0.9)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use a ```BN``` LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* modify the ```LeNet``` model in order to apply the batch normalization layer.\n",
    "    * Conv -> ```BN``` -> activation \n",
    "    * Linear -> ```BN``` -> activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Conv2d(1, 6, kernel_size=5),  # Conv\n",
    "                    BatchNorm(6, num_dims=4),        # BN \n",
    "                    nn.Sigmoid(),                    # activation \n",
    "                    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                    nn.Conv2d(6, 16, kernel_size=5),\n",
    "                    BatchNorm(16, num_dims=4),\n",
    "                    nn.Sigmoid(),\n",
    "                    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                    Flatten(),\n",
    "                    nn.Linear(16*4*4, 120),\n",
    "                    BatchNorm(120, num_dims=2),\n",
    "                    nn.Sigmoid(),\n",
    "                    nn.Linear(120, 84),\n",
    "                    BatchNorm(84, num_dims=2),\n",
    "                    nn.Sigmoid(),\n",
    "                    nn.Linear(84, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "* Check the model design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape:\t torch.Size([1, 6, 24, 24])\n",
      "BatchNorm output shape:\t torch.Size([1, 6, 24, 24])\n",
      "Sigmoid output shape:\t torch.Size([1, 6, 24, 24])\n",
      "MaxPool2d output shape:\t torch.Size([1, 6, 12, 12])\n",
      "Conv2d output shape:\t torch.Size([1, 16, 8, 8])\n",
      "BatchNorm output shape:\t torch.Size([1, 16, 8, 8])\n",
      "Sigmoid output shape:\t torch.Size([1, 16, 8, 8])\n",
      "MaxPool2d output shape:\t torch.Size([1, 16, 4, 4])\n",
      "Flatten output shape:\t torch.Size([1, 256])\n",
      "Linear output shape:\t torch.Size([1, 120])\n",
      "BatchNorm output shape:\t torch.Size([1, 120])\n",
      "Sigmoid output shape:\t torch.Size([1, 120])\n",
      "Linear output shape:\t torch.Size([1, 84])\n",
      "BatchNorm output shape:\t torch.Size([1, 84])\n",
      "Sigmoid output shape:\t torch.Size([1, 84])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(size=(1,1,28,28), dtype = torch.float32)   # [B, C, H, W]\n",
    "\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "* Data Acquisition \n",
    "* Reading Data (Fashion-MNIST)\n",
    "* Preprocess: Fashion-MNIST has 28x28 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os \n",
    "\n",
    "import torchvision \n",
    "from torchvision import transforms \n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None, root=os.path.join(os.getcwd(), 'datasets', 'fashion-mnist')):\n",
    "    \"\"\"Download the Fashion-MNIST dataset and then load into memory.\"\"\"\n",
    "    root = os.path.expanduser(root)\n",
    "    transformer = []\n",
    "    if resize:\n",
    "        transformer += [transforms.Resize(resize)]\n",
    "    transformer += [transforms.ToTensor()]\n",
    "    transformer = transforms.Compose(transformer)\n",
    "\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, transform=transformer, download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, transform=transformer, download=True)\n",
    "    num_workers = 0 if sys.platform.startswith('win32') else 4\n",
    "\n",
    "    train_iter = DataLoader(mnist_train, batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_iter = DataLoader(mnist_test, batch_size, shuffle=False, num_workers=num_workers)\n",
    "    return train_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "#Loading Fashion-MNIST Dataset\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "* Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu():\n",
    "    \"\"\"If GPU is available, return torch.device as cuda:0; else return torch.device as cpu.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, device=torch.device('cpu')):\n",
    "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
    "    net.eval()  # Switch to evaluation mode for Dropout, BatchNorm etc layers.\n",
    "    acc_sum, n = torch.tensor([0], dtype=torch.float32, device=device), 0\n",
    "    for X, y in data_iter:\n",
    "        # Copy the data to device.\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            y = y.long()\n",
    "            acc_sum += torch.sum((torch.argmax(net(X), dim=1) == y))\n",
    "            n += y.shape[0]\n",
    "    return acc_sum.item()/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ch5(net, train_iter, test_iter, criterion, num_epochs, batch_size, device, lr=None):\n",
    "    \"\"\"Train and evaluate a model with CPU or GPU.\"\"\"\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train() # Switch to training mode\n",
    "        n, start = 0, time.time()\n",
    "        train_l_sum = torch.tensor([0.0], dtype=torch.float32, device=device)\n",
    "        train_acc_sum = torch.tensor([0.0], dtype=torch.float32, device=device)\n",
    "        for X, y in train_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, y = X.to(device), y.to(device) \n",
    "            y_hat = net(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                y = y.long()\n",
    "                train_l_sum += loss.float()\n",
    "                train_acc_sum += (torch.sum((torch.argmax(y_hat, dim=1) == y))).float()\n",
    "                n += y.shape[0]\n",
    "\n",
    "        test_acc = evaluate_accuracy(test_iter, net, device) \n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\\\n",
    "            % (epoch + 1, train_l_sum/n, train_acc_sum/n, test_acc, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs, batch_size, device = 1, 5, 256, try_gpu()\n",
    "\n",
    "#Xavier initialization of weights\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.apply(init_weights)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda:0\n",
      "epoch 1, loss 0.0025, train acc 0.766, test acc 0.723, time 3.2 sec\n",
      "epoch 2, loss 0.0016, train acc 0.853, test acc 0.757, time 3.0 sec\n",
      "epoch 3, loss 0.0014, train acc 0.870, test acc 0.767, time 3.1 sec\n",
      "epoch 4, loss 0.0013, train acc 0.880, test acc 0.786, time 2.8 sec\n",
      "epoch 5, loss 0.0012, train acc 0.887, test acc 0.802, time 2.9 sec\n"
     ]
    }
   ],
   "source": [
    "#Loss Function Criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_ch5(net, train_iter, test_iter, criterion, num_epochs, batch_size, device, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* look at the scale parameter ***gamma*** and the shift parameter ***beta*** learned from the first ```BN``` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.6446, 0.8415, 1.5868, 1.0924, 1.9643, 1.2396], device='cuda:0',\n",
       "        grad_fn=<ViewBackward>),\n",
       " tensor([-0.0330,  0.1842, -1.5372, -0.8181,  0.4079, -1.0140], device='cuda:0',\n",
       "        grad_fn=<ViewBackward>))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.children())[1].gamma.reshape((-1,)), list(net.children())[1].beta.reshape((-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "* Concise Implementation \n",
    "* Compared with the BatchNorm class, which we just defined ourselves, the _BatchNorm class defined by the ```nn.modules.batchnorm``` model in Pytorch is easier to use\n",
    "* ```nn.BatchNorm1d``` and ```nn.BatchNorm2d``` for num_dims= 2 and 4 respectively. \n",
    "* The number of features is to be passed as argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = nn.Sequential(nn.Conv2d(1, 6, kernel_size=5),\n",
    "                    nn.BatchNorm2d(6),\n",
    "                    nn.Sigmoid(),\n",
    "                    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                    nn.Conv2d(6, 16, kernel_size=5),\n",
    "                    nn.BatchNorm2d(16),\n",
    "                    nn.Sigmoid(),\n",
    "                    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                    Flatten(),\n",
    "                    nn.Linear(256, 120),\n",
    "                    nn.BatchNorm1d(120),\n",
    "                    nn.Sigmoid(),\n",
    "                    nn.Linear(120, 84),\n",
    "                    nn.BatchNorm1d(84),\n",
    "                    nn.Sigmoid(),\n",
    "                    nn.Linear(84, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note that as usual, the Pytorch variant runs much faster since its code has been compiled to C++/CUDA versus our custom implementation, which must be interpreted by Python.\n",
    "* 처리 속도 보면 ```nn.modules.batchnorm```이 더 빠르지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2.apply(init_weights)\n",
    "net2 = net2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda:0\n",
      "epoch 1, loss 0.0026, train acc 0.760, test acc 0.777, time 2.0 sec\n",
      "epoch 2, loss 0.0016, train acc 0.852, test acc 0.809, time 2.0 sec\n",
      "epoch 3, loss 0.0014, train acc 0.872, test acc 0.750, time 1.9 sec\n",
      "epoch 4, loss 0.0013, train acc 0.879, test acc 0.739, time 2.0 sec\n",
      "epoch 5, loss 0.0012, train acc 0.885, test acc 0.710, time 1.9 sec\n"
     ]
    }
   ],
   "source": [
    "#Loss Function Criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_ch5(net2, train_iter, test_iter, criterion, num_epochs, batch_size, device, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env] *",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
