{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D correlation function \n",
    "\n",
    "def corr2d(X, K):  \n",
    "    \"\"\"\n",
    "    X : input \n",
    "    K : kernel \n",
    "    \"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i: i + h, j: j + w] * K).sum() # sum of element-wise product\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.Tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "K = torch.Tensor([[0, 1], [2, 3]])\n",
    "\n",
    "corr2d(X, K) # correlation function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* import ```torch.nn``` package for convolution layer \n",
    "* The parameters of the convolutional layer are precisely the values that constitute the kernel and the scalar bias. \n",
    "* The forward computation function ```forward``` calls the ```corr2d``` function and adds the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  we declare ```weight``` and ```bias``` as the two model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size, **kwargs):\n",
    "        super(Conv2D, self).__init__(**kwargs)\n",
    "        \n",
    "        self.weight = torch.rand(kernel_size,dtype=torch.float32, requires_grad=True)\n",
    "        self.bias = torch.zeros((1,), dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Object Edge Detection in Images \n",
    "* ***Conv layer***: detecting the edge of an object in an image by finding the location of the pixel change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones((6, 8))   # 6x8 shape \n",
    "X[:, 2:6] = 0            # [white, Black, white ]\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* kernel K with a height of 1 and width of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.Tensor([[1, -1]]) # kenel = [1, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using ```corr2d``` function \n",
    "* Using ```Conv2D``` layer \n",
    "* Compare them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = corr2d(X, K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.t()     # [white, \n",
    "          #  black, \n",
    "          #  white]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's apply the kernel to the transposed image. As expected, it vanishes. The kernel K only detects vertical edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d(X.t(), K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Learning a Kernel \n",
    "* First, construct a convolutional layer and initialize its kernel as a random array\n",
    "* In each iteration, we will use the squared error to compare Y and the output of the convolutional layer\n",
    "* Then, calculate the gradient to update the weight\n",
    "\n",
    "Ignores the bias for simplicity in this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2, loss 0.992\n",
      "batch 4, loss 0.197\n",
      "batch 6, loss 0.045\n",
      "batch 8, loss 0.013\n",
      "batch 10, loss 0.004\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- Construct a convolutional layer with 1 output channel\n",
    "(channels will be introduced in the following section)\n",
    "- and a kernel array shape of (1, 2)\n",
    "\"\"\"\n",
    "\n",
    "conv2d = nn.Conv2d(in_channels=1,out_channels=1, kernel_size=(1, 2),bias=False) #For sake of simplicity ignoring bias\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The two-dimensional convolutional layer uses four-dimensional input and\n",
    "output in the format of (example channel, height, width), where the batch\n",
    "size (number of examples in the batch) and the number of channels are both 1\n",
    "\"\"\"\n",
    "X = X.reshape((1, 1, 6, 8))   # [B, C, H, W] = [1, 1, 6, 8]\n",
    "Y = Y.reshape((1, 1, 6, 7))\n",
    "\n",
    "\n",
    "for i in range(10):      # 10-iteration \n",
    "    Y_hat = conv2d(X)    # prediction \n",
    "    l = (Y_hat - Y) ** 2 # Squared Error\n",
    "   \n",
    "    conv2d.zero_grad()   # init. zero_grad \n",
    "    l.sum().backward()   \n",
    "    \n",
    "    # For the sake of simplicity, we ignore the bias here\n",
    "    conv2d.weight.data[:] -= 3e-2 * conv2d.weight.grad   # weight update\n",
    "                                                         # w <- w - a*(dLoss/dw)\n",
    "    \n",
    "    if (i + 1) % 2 == 0:\n",
    "        print('batch %d, loss %.3f' % (i + 1, l.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* the error has dropped to a small value after 10 iterations. \n",
    "* Now, we will take a look at the kernel array we learned.\n",
    "\n",
    "\n",
    "ndeed, the learned kernel array is remarkably close to the kernel array K=\\[1, -1\\] we defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0013, -0.9890]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.data.reshape((1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env] *",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
