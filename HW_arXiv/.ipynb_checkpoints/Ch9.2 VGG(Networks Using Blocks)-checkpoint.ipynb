{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* VGG block (basic building block) \n",
    "* Simplified version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(num_convs, in_channels, out_channels):\n",
    "    layers=[]\n",
    "    for _ in range(num_convs):\n",
    "        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "        in_channels = out_channels\n",
    "    \n",
    "    layers.append(nn.MaxPool2d(kernel_size=2,stride=2))\n",
    "    \n",
    "    blk = nn.Sequential(*layers)\n",
    "    \n",
    "    return blk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* the VGG Network can be partitioned into two parts:\n",
    "    * (1st) consisting mostly of ```convolutional``` and ```pooling``` layers \n",
    "    * (2nd) consisting of ```fully-connected``` linear layers\n",
    "\n",
    "* The convolutional portion of the net connects several ```vgg_block``` modules in succession. \n",
    "\n",
    "<br/> \n",
    "\n",
    "* the variable ```conv_arch``` consists of a list of tuples (one per block), where each contains two values:\n",
    "    * (1) the number of convolutional layers\n",
    "    * (2) the number of output channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Implement ```VGG-11```\n",
    "* This is a simple matter of executing a for loop over ```conv_arch```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], -1)\n",
    "    \n",
    "def vgg(conv_arch):\n",
    "    # The convulational layer part\n",
    "    conv_layers=[]\n",
    "    in_channels=1\n",
    "    \n",
    "    for (num_convs, out_channels) in conv_arch:\n",
    "        conv_layers.append(vgg_block(num_convs, in_channels, out_channels))\n",
    "        in_channels = out_channels\n",
    "    \n",
    "    net=nn.Sequential(\n",
    "                      *conv_layers,\n",
    "                      # The fully connected layer part\n",
    "                      Flatten(),\n",
    "                      nn.Linear(in_features=512*7*7, out_features=4096),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.5),\n",
    "                      nn.Linear(4096, 4096),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.5),\n",
    "                      nn.Linear(4096, 10)\n",
    "                     )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = vgg(conv_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In order to Check the model \n",
    "* Construct a single-channel data example with a height and width of 224 to observe the output shape of each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 112, 112])\n",
      "Sequential output shape:\t torch.Size([1, 128, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 256, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 512, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 512, 7, 7])\n",
      "Flatten output shape:\t torch.Size([1, 25088])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(size=(1,1,224,224), dtype=torch.float32)\n",
    "\n",
    "for blk in net:\n",
    "    X = blk(X)\n",
    "    print(blk.__class__.__name__,'output shape:\\t',X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reading Data (Fashion-MNIST)\n",
    "* Preprocess: Fashion-MNIST has 28x28 pixels -> upsample them to 244x244"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os \n",
    "\n",
    "import torchvision \n",
    "from torchvision import transforms \n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None, root=os.path.join(os.getcwd(), 'datasets', 'fashion-mnist')):\n",
    "    \"\"\"Download the Fashion-MNIST dataset and then load into memory.\"\"\"\n",
    "    root = os.path.expanduser(root)\n",
    "    transformer = []\n",
    "    if resize:\n",
    "        transformer += [transforms.Resize(resize)]\n",
    "    transformer += [transforms.ToTensor()]\n",
    "    transformer = transforms.Compose(transformer)\n",
    "\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, transform=transformer, download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, transform=transformer, download=True)\n",
    "    num_workers = 0 if sys.platform.startswith('win32') else 4\n",
    "\n",
    "    train_iter = DataLoader(mnist_train, batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_iter = DataLoader(mnist_test, batch_size, shuffle=False, num_workers=num_workers)\n",
    "    return train_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu():\n",
    "    \"\"\"If GPU is available, return torch.device as cuda:0; else return torch.device as cpu.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, device=torch.device('cpu')):\n",
    "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
    "    net.eval()  # Switch to evaluation mode for Dropout, BatchNorm etc layers.\n",
    "    acc_sum, n = torch.tensor([0], dtype=torch.float32, device=device), 0\n",
    "    for X, y in data_iter:\n",
    "        # Copy the data to device.\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            y = y.long()\n",
    "            acc_sum += torch.sum((torch.argmax(net(X), dim=1) == y))\n",
    "            n += y.shape[0]\n",
    "    return acc_sum.item()/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ch5(net, train_iter, test_iter, criterion, num_epochs, batch_size, device, lr=None):\n",
    "    \"\"\"Train and evaluate a model with CPU or GPU.\"\"\"\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train() # Switch to training mode\n",
    "        n, start = 0, time.time()\n",
    "        train_l_sum = torch.tensor([0.0], dtype=torch.float32, device=device)\n",
    "        train_acc_sum = torch.tensor([0.0], dtype=torch.float32, device=device)\n",
    "        for X, y in train_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, y = X.to(device), y.to(device) \n",
    "            y_hat = net(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                y = y.long()\n",
    "                train_l_sum += loss.float()\n",
    "                train_acc_sum += (torch.sum((torch.argmax(y_hat, dim=1) == y))).float()\n",
    "                n += y.shape[0]\n",
    "\n",
    "        test_acc = evaluate_accuracy(test_iter, net, device) \n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\\\n",
    "            % (epoch + 1, train_l_sum/n, train_acc_sum/n, test_acc, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs, batch_size, device = 0.05, 5, 64, try_gpu()\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.apply(init_weights)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda:0\n",
      "epoch 1, loss 0.0112, train acc 0.736, test acc 0.856, time 387.9 sec\n",
      "epoch 2, loss 0.0052, train acc 0.879, test acc 0.836, time 284.0 sec\n",
      "epoch 3, loss 0.0042, train acc 0.901, test acc 0.906, time 284.4 sec\n",
      "epoch 4, loss 0.0037, train acc 0.914, test acc 0.908, time 284.8 sec\n",
      "epoch 5, loss 0.0032, train acc 0.925, test acc 0.914, time 285.1 sec\n"
     ]
    }
   ],
   "source": [
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_ch5(net, train_iter, test_iter, criterion, num_epochs, batch_size, device, lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env] *",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
