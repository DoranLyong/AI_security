{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Multiple Output Channels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X, K):\n",
    "    \"\"\"\n",
    "    Compute 2D cross-correlation.\n",
    "    K: kernel \n",
    "    \"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in(X, K):\n",
    "    \"\"\"\n",
    "     First, traverse along the 0th dimension (channel dimension) of X and K. \n",
    "     Then, add them together by using python sum() function\n",
    "     which takes in a list as an argument\n",
    "    \"\"\"\n",
    "    \n",
    "    return sum([corr2d(x, k) for x, k in zip(X, K)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[[0, 1, 2], [3, 4, 5], [6, 7, 8]],\n",
    "                  [[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n",
    "K = torch.tensor([[[0, 1], [2, 3]],\n",
    "                  [[1, 2], [3, 4]]])\n",
    "\n",
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement a cross-correlation function to calculate the output of multiple channels as shown below.<br/>\n",
    "We construct a convolution kernel with 3 output channels by concatenating the kernel array K with K+1 (plus one for each element in K) and K+2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    \"\"\"\n",
    "    # Traverse along the 0th dimension of K(kernel), and each time, perform\n",
    "    # cross-correlation operations with input X. All of the results are merged\n",
    "    # together using the stack function\n",
    "    \"\"\"\n",
    "    \n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = torch.stack([K, K + 1, K + 2], dim=0)\n",
    "\n",
    "K.shape   # [Batch, Channel, Height, Width]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Now the output contains 3 channels. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X, K)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Convolutional Layer \n",
    "* mplement the $1 \\times 1$ convolution using a fully-connected layer\n",
    "\n",
    "The only thing is that we need to make some adjustments to the data shape before and after the matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    \n",
    "    X = X.reshape((c_i, h * w))  # Conv -> fully-connected \n",
    "    K = K.reshape((c_o, c_i))\n",
    "    \n",
    "    Y = torch.mm(K, X)  # Matrix multiplication in the fully connected layer for Conv2D\n",
    "    return Y.reshape((c_o, h, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When performing $1\\times 1$ convolution, <br/>the above function is equivalent to the previously implemented cross-correlation function ```corr2d_multi_in_out```. <br/>\n",
    "\n",
    "2D Conv concept formula  vs.  tricky 2D Conv with fully-connected -> those are the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(size=(3, 3, 3))     # (C, H, W) = (3, 3, 3)\n",
    "K = torch.randn(size=(2, 3, 1, 1))  # (B, C, H, W) = (2, 3, 1, 1)\n",
    "\n",
    "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
    "Y2 = corr2d_multi_in_out(X, K)\n",
    "\n",
    "(Y1 - Y2).norm().item() < 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env] *",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
